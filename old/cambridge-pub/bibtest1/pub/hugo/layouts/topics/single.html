
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
   "http://www.w3.org/TR/html4/loose.dtd">

<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<title>Machine Learning Group Publications</title>

<style type="text/css">
body {font-family: Verdana,Arial,Helvetica,sans-serif; font-size: 15px}
p.c {margin-left: 1cm; margin-right: 0cm; text-align: justify; font-size: 12px}
p.s {font-size: 12px}
</style>

</head>
<body text="#000000" link="#0000ff" vlink="#a020f0" alink="#ff0000"> 

<center><h2>Publications, <a href="../../">Machine Learning Group</a>, Department of Engineering, Cambridge</h2></center><br>

{{ partial "head-icons.html" }}

{{ partial "head-authors.html"}}

{{ partial "head-year.html"}}

<table border=0 cellpadding=10>
<tr valign="top">
<td><img src="../icons/gp.png" border=0 alt="GP" align="middle" width=76>
<td><h3 id="gp">Gaussian Processes and Kernel Methods</h3>
Gaussian processes are <a href="#np">non-parametric</a> distributions useful
for doing Bayesian inference and learning on unknown functions.
They can be used for non-linear regression, time-series modelling,
classification, and many other problems.</table><br>
{{ partial "ref-gp.html" }}
<br>

<table border=0 cellpadding=10>
<tr valign="top">
<td><img src="../icons/clustering.png" border=0 alt="Clustering"
align="middle" width=76>
<td><h3 id="clust">Clustering</h3>
Clustering algorithms are unsupervised methods for finding groups of
similar points in data. They are closely related to statistical mixture
models.</table><br>
{{ partial "ref-clust.html" }}
<br>

<table border=0 cellpadding=10>
<tr valign="top">
<td><img src="../icons/gm.png" border=0 alt="Graphical Models"
 align="middle" width=76>
<td><h3 id="gm">Graphical Models</h3>
Graphical models are a graphical representation of the conditional
independence relations among a set of variables. The graph is useful
both as an intuitive representation of how the variables are related,
and as a tool for defining efficient message passing algorithms for
probabilistic inference.</table><br>
{{ partial "ref-gm.html" }}
<br>

<table border=0 cellpadding=10>
<tr valign="top">
<td><img src="../icons/mcmc.png" border=0 alt="Monte Carlo"
 align="middle" width=76>
<td><h3 id="mcmc">Monte Carlo Methods</h3>
Markov chain Monte Carlo (MCMC) methods use sampling to approximate
high dimensional integrals and intractable sums. MCMC methods are widely
used in many areas of science, applied mathematics and engineering. They
are an indispensable approximate inference tool for Bayesian statistics
and machine learning.</table><br>
{{ partial "ref-mcmc.html" }}
<br>

<table border=0 cellpadding=10>
<tr valign="top">
<td><img src="../icons/ssl.png" border=0 alt="Semi-Supervised"
 align="middle" width=76>
<td><h3 id="ssl">Semi-Supervised Learning</h3>
Often, it is easy and cheap to obtain large amounts of unlabelled
data (e.g. images, text documents), while it is hard or expensive
to obtain labelled data. Semi-supervised learning methods attempt to
use the unlabelled data to improve the performance on supervised
learning tasks, such as classification.</table><br>
{{partial "ref-ssl.html" }}
<br>

<table border=0 cellpadding=10>
<tr valign="top">
<td><img src="../icons/nonparam.png" border=0 alt="Non-Parametric"
 align="middle" width=76>
<td><h3 id="np">Non-parametric Bayesian Learning</h3>
Non-parametric models are very flexible statistical models in which the
complexity of the model grows with the amount of observed data. While
traditional parametric models make strong assumptions about how the data
was generated, non-parametric models try to make weaker assumptions and
let the data "speak for itself". Many non-parametric models can be seen
as infinite limits of finite parametric models, and an important family
of non-parametric models are derived from Dirichlet processes. See also
<a href="#gp">Gaussian Processes</a>.</table><br>
{{ partial "ref-np.html" }}
<br>

<table border=0 cellpadding=10>
<tr valign="top">
<td><img src="../icons/approx.png" border=0 alt="Approximations"
 align="middle" width=76>
<td><h3 id="approx">Approximate Inference</h3>
For all but the simplest statistical models, exact learning and inference
are computationally intractable. Approximate inference methods make it
possible to learn realistic models from large data sets. Generally,
approximate inference methods trade off computation time for accuracy.
Some of the major classes of approximate inference methods include
<a href="#mcmc"> Markov chain Monte Carlo</a> methods, variational methods
and related algorithms such as Expectation Propagation.</table><br>
{{partial "ref-approx.html" }}
<br>

<table border=0 cellpadding=10>
<tr valign="top">
<td><img src="../icons/bioinf.png" border=0 alt="Bioinformatics"
 align="middle" width=76>
<td><h3 id="bioinf">Bioinformatics</h3>
Recent advances in biology have allowed us to collect vast amounts of
genetic, proteomic and biomedical data. While this data offers the
potential to help us understand the building blocks of life, and to
revolutionise medicine, analysing and understanding it poses immense
computational and statistical challenges. Our work in Bionformatics
includes modelling protein secondary and tertiary structure, analysis
of gene microarray data, protein-protein interactions, and biomarker
discovery.</table><br>
{{partial "ref-bioinf.html" }}
<br>

<table border=0 cellpadding=10>
<tr valign="top">
<td><img src="../icons/ir.png" border=0 alt="Information Retrieval"
 align="middle" width=76>
<td><h3 id="ir">Information Retrieval</h3>
Information retrieval concerns develping systems that find material
from within a large unstructured collection (e.g. the internet) that
satisfy the user's need. The best example of such systems are web search
engines, such as Google, but there are many other specialized applications
of information retrieval (such as collaborative filtering and recommender
systems). Information retrieval can be thought of as an inference problem:
given the user's query, what are the relevant items in the data collection?
</table><br>
{{partial "ref-ir.html" }}
<br>

<table border=0 cellpadding=10>
<tr valign="top">
<td><img src="../icons/motor.png" border=0 alt="Reinforcement Learning"
 align="middle" width=76>
<td><h3 id="rl">Reinforcement Learning and Control</h3>
We are interested in understanding the human sensory motor system
from a mathematical, computational and engineering point of view.
To do this, we need to use concepts from control theory, optimization,
machine learning and statistics, as well as experimental methods based
on human psychophysics and virtual reality. These formal tools are also
useful for advancing robotics and decision theory.</table><br>
{{partial "ref-rl.html" }}
<br>

<table border=0 cellpadding=10>
<tr valign="top">
<td><img src="../icons/timeseries.png" border=0 alt="Time Series"
 align="middle" width=76>
<td><h3 id="time">Time Series Models</h3>
Modelling time series and sequential data is an essential part of many
different areas of science and engineering, including for example,
signal processing and control, bioinformatics, speech recognition,
econometrics and finance. Using basic building blocks such as hidden
Markov models, linear Gaussian state-space models, and Bayesian networks,
it is possible to develop sophisticated time series models for real
world data. However learning (parameter inference / system identification)
becomes computationally challenging for such sophisticated models.
</table><br>
{{partial "ref-time.html" }}
<br>

<table border=0 cellpadding=10>
<tr valign="top">
<td><img src="../icons/networkModelling.png" border=0 alt="Network Modelling"
 align="middle" width=76>
<td><h3 id="network">Network Modelling</h3></table>
{{partial "ref-network.html" }}

<table border=0 cellpadding=10>
<tr valign="top">
<td><img src="../icons/active.png" border=0 alt="Active Learning"
 align="middle" width=76>
<td><h3 id="active">Active Learning</h3></table>
{{partial "ref-active.html" }}

<table border=0 cellpadding=10>
<tr valign="top">
<td><img src="../icons/neuroscience.png" border=0 alt="Neuroscience"
 align="middle" width=76>
<td><h3 id="neuro">Neuroscience</h3></table>
{{partial "ref-neuro.html" }}

<table border=0 cellpadding=10>
<tr valign="top">
<td><img src="../icons/signalProcessing.png" border=0 alt="Signal Processing"
 align="middle" width=76>
<td><h3 id="sigproc">Signal Processing</h3></table>
{{partial "ref-sigproc.html" }}

<table border=0 cellpadding=10>
<tr valign="top">
<td><img src="../icons/machineVision.png" border=0 alt="Machine Vision"
 align="middle" width=76>
<td><h3 id="mvision">Machine Vision</h3></table>
{{partial "ref-mvision.html" }}

<table border=0 cellpadding=10>
<tr valign="top">
<td><img src="../icons/machineHearing.png" border=0 alt="Machine Hearning"
 align="middle" width=76>
<td><h3 id="mhearing">Machine Hearing</h3></table>
{{partial "ref-mhearing.html" }}

<table border=0 cellpadding=10>
<tr valign="top">
<td><img src="../icons/nlp.png" border=0 alt="Natural Language Processing"
 align="middle" width=76>
<td><h3 id="nlp">Natural Language Processing</h3></table>
{{partial "ref-nlp.html" }}

<table border=0 cellpadding=10>
<tr valign="top">
<td><img src="../icons/deepLearning.png" border=0 alt="Deep Learning"
 align="middle" width=76>
<td><h3 id="deep">Deep Learning</h3></table>
{{partial "ref-deep.html" }}

<table border=0 cellpadding=10>
<tr valign="top">
<td><img src="../icons/fairness.png" border=0 alt="Fairness"
 align="middle" width=76>
<td><h3 id="fairness">Fairness</h3></table>
{{partial "ref-fairness.html" }}

<table border=0 cellpadding=10>
<tr valign="top">
<td><img src="../icons/interpretability.png" border=0 alt="Interpretability"
 align="middle" width=76>
<td><h3 id="interpretability">Interpretability</h3></table>
{{partial "ref-interpretability.html" }}

<table border=0 cellpadding=10>
<tr valign="top">
<td><img src="../icons/reviews.png" border=0 alt="Reviews"
 align="middle" width=76>
<td><h3 id="review">Review Articles and Tutorials</h3></table>
{{partial "ref-review.html" }}

</body>
</html>
